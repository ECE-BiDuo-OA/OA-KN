{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab 7. Deep Learning Software - Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsSKTz6gASFg"
      },
      "source": [
        "Made by the team :\n",
        "*   Kishor JOGARAJAH\n",
        "*   Neil SEGARD\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1jubjRgFVVlET8izn0N0vFhwj1s7toVH2\n",
        "    \n",
        "*This code is based on the code in your courses*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpuWjWi1A17F"
      },
      "source": [
        "## Importation & definition\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_nnh5xuAqGm"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def getData(file):\n",
        "    data = np.loadtxt(fname = file)\n",
        "    X=data[:,:3]\n",
        "    YData=data[:,3:]\n",
        "\n",
        "    #Formatting Y\n",
        "    Y=[]\n",
        "    YUnique=np.unique(YData)\n",
        "\n",
        "    for y in YData:\n",
        "        Y.append((YUnique==y[0])*1)\n",
        "\n",
        "    Y=np.asarray(Y)\n",
        "\n",
        "    return X, Y, YUnique, YData\n",
        "\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, n_feature, n_hidden, n_output):\n",
        "        super(Net, self).__init__()\n",
        "        self.hidden = torch.nn.Linear(n_feature, n_hidden) # hidden layer\n",
        "        self.out = torch.nn.Linear(n_hidden, n_output) # output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.sigmoid(self.hidden(x)) # activation function for hidden layer\n",
        "        # x = F.sigmoid(self.hidden(x)) # activation function for hidden layer\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehYJRWycBTtW"
      },
      "source": [
        "############# INITIALIZING #############\n",
        "#Getting X and Y\n",
        "X, Y, YUnique, Ydata = getData(\"https://raw.githubusercontent.com/ECE-BiDuo-OA/OA-KN/main/7.%20Deep%20Learning%20Software%20-%20Pytorch/data_ffnn_3classes.txt\")\n",
        "\n",
        "K=10\n",
        "learning_rate=0.02\n",
        "nbEpoch=500"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXXFB5atBP8E"
      },
      "source": [
        "## Q1\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGFQ3eUZbLxu",
        "outputId": "60f410d1-1e08-4645-ccb6-bfd3b56d64af"
      },
      "source": [
        "print(\"We have {} different categories\\n\".format(len(YUnique)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q1\n",
            "We have 3 different categories\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr1Uk13LBsUY"
      },
      "source": [
        "## Q2&3\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdDh1uDHBdxD",
        "outputId": "01e39715-c0b8-4a67-ca4f-81c0c1ce57db"
      },
      "source": [
        "torch.manual_seed(1) # reproducible\n",
        "# sample data preparation\n",
        "Ydata=Ydata.reshape(len(Ydata))\n",
        "x = torch.tensor(X).type(torch.FloatTensor)\n",
        "y = torch.tensor(Ydata).type(torch.LongTensor)\n",
        "\n",
        "# torch need to train on Variable, so convert sample features to Variable\n",
        "x, y = Variable(x), Variable(y)\n",
        "\n",
        "\n",
        "net = Net(n_feature=3, n_hidden=K, n_output=3) # define the network\n",
        "# net.double()\n",
        "#print(net) # Neural network architecture\n",
        "\n",
        "# Loss and optimizer\n",
        "# Softmax is internally computed.\n",
        "# Set parameters to be updated\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
        "loss_func = torch.nn.CrossEntropyLoss() # the target label is not an one-hotted.\n",
        "#print(optimizer)\n",
        "#print(loss_func)\n",
        "\n",
        "# turn the interactive mode on\n",
        "plt.ion()\n",
        "\n",
        "\n",
        "for t in range(nbEpoch):\n",
        "    out = net(x) # input x and predict based on x\n",
        "    loss = loss_func(out, y) # must be (1. nn output, 2. target)\n",
        "    optimizer.zero_grad() # clear gradients for next train\n",
        "    loss.backward() # backpropagation, compute gradients\n",
        "    optimizer.step() # apply gradients\n",
        "\n",
        "    if t % 10 == 0:\n",
        "        # show learning process\n",
        "        _, prediction = torch.max(F.softmax(out),1)\n",
        "        pred_y = prediction.data.numpy().squeeze()\n",
        "        target_y = y.data.numpy()\n",
        "        error = sum(pred_y != target_y)\n",
        "        accuracy = 1 - error/len(X)\n",
        "\n",
        "        print(\"Epoch={:3d}, Error={:2d}, Accuracy={:.2f} %\".format(t, error, accuracy*100))\n",
        "\n",
        "        if accuracy==1.0:\n",
        "          break\n",
        "\n",
        "plt.ioff()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch=  0, Error=40, Accuracy=43.66 %\n",
            "Epoch= 10, Error=40, Accuracy=43.66 %\n",
            "Epoch= 20, Error=39, Accuracy=45.07 %\n",
            "Epoch= 30, Error=23, Accuracy=67.61 %\n",
            "Epoch= 40, Error=20, Accuracy=71.83 %\n",
            "Epoch= 50, Error=20, Accuracy=71.83 %\n",
            "Epoch= 60, Error=20, Accuracy=71.83 %\n",
            "Epoch= 70, Error=20, Accuracy=71.83 %\n",
            "Epoch= 80, Error=20, Accuracy=71.83 %\n",
            "Epoch= 90, Error=20, Accuracy=71.83 %\n",
            "Epoch=100, Error=18, Accuracy=74.65 %\n",
            "Epoch=110, Error=13, Accuracy=81.69 %\n",
            "Epoch=120, Error= 7, Accuracy=90.14 %\n",
            "Epoch=130, Error= 4, Accuracy=94.37 %\n",
            "Epoch=140, Error= 1, Accuracy=98.59 %\n",
            "Epoch=150, Error= 1, Accuracy=98.59 %\n",
            "Epoch=160, Error= 1, Accuracy=98.59 %\n",
            "Epoch=170, Error= 1, Accuracy=98.59 %\n",
            "Epoch=180, Error= 0, Accuracy=100.00 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olm5er-qBvUx"
      },
      "source": [
        "## Q4\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXXH3niTBdzg",
        "outputId": "4de8d78f-f8d5-443c-8f3f-c83a38e5237f"
      },
      "source": [
        "out = net(x) # input x and predict based on x\n",
        "_, prediction = torch.max(F.softmax(out),1)\n",
        "pred_y = prediction.data.numpy().squeeze()\n",
        "target_y = y.data.numpy()\n",
        "\n",
        "for p,t in zip(pred_y,target_y):\n",
        "  print(\"Target: {}    Predicted: {}    {}\".format(t, p, \"MATCH\" if p==t else \"NOT MATCH\"))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 1    Predicted: 1    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 0    Predicted: 0    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n",
            "Target: 2    Predicted: 2    MATCH\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN3ukhjIBwmr"
      },
      "source": [
        "## Q5\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0Ty3D-aeAng",
        "outputId": "500fea54-379d-4c96-ed6e-c6480684b342"
      },
      "source": [
        "XTest=[[2, 2, -3],[3, 4, 3],[4.5, 1.5, 0]]\n",
        "xtext = torch.tensor(XTest).type(torch.FloatTensor)\n",
        "xtext = Variable(xtext)\n",
        "\n",
        "out = net(xtext) # input x and predict based on x\n",
        "_, prediction = torch.max(F.softmax(out),1)\n",
        "pred_y = prediction.data.numpy().squeeze()\n",
        "\n",
        "print(\" X1   X2   X3     Y (predicted)\")\n",
        "for xt, yp in zip(XTest, pred_y):\n",
        "    print(\"{:< 5.1f}{:< 5.1f}{:< 5.1f}   {:d}\".format(xt[0],xt[1],xt[2],yp))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " X1   X2   X3     Y (predicted)\n",
            " 2.0  2.0 -3.0    0\n",
            " 3.0  4.0  3.0    1\n",
            " 4.5  1.5  0.0    2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}